# Robust LLM-based Audio-Visual Speech Recognition with Sparse Modality Alignment and Visual Unit-Guided Refinement

This repository currently provides checkpoints for the paper **"Robust LLM-based Audio-Visual Speech Recognition with Sparse Modality Alignment and Visual Unit-Guided Refinement"**.
We plan to release the training code after the paper is formally accepted.

## Installation

Our model integrates the Whisper and AV-HuBERT encoders with large language models (LLMs), supporting Automatic Speech Recognition (ASR), Visual Speech Recognition (VSR), and Audio-Visual Speech Recognition (AVSR). The source code and environment configuration instructions will be released upon the formal acceptance of the paper.

## Checkpoints

The model checkpoints are available for download. Use the following link to access the checkpoints:

**Baidu Netdisk Link:** [https://pan.baidu.com/s/1znIvukPku5InwtqN09KWBg?pwd=jaw5](https://pan.baidu.com/s/1znIvukPku5InwtqN09KWBg?pwd=jaw5)  
**Extraction Code:** jaw5


